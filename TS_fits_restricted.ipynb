{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "This choice will generate autonomous dynamics\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cpu'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from models.training import create_dataloader\n",
    "import scipy.io as io\n",
    "\n",
    "\n",
    "# Juptyer magic: For export. Makes the plots size right for the screen \n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg'] \n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "seed = np.random.randint(1,200)\n",
    "seed = 56\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "print(seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "# design choices \n",
    "chosen_problem = 'restricted_TS'\n",
    "data_noise = 0.\n",
    "n_different_weights = 1\n",
    "if n_different_weights == 1:\n",
    "    print('This choice will generate autonomous dynamics')\n",
    "else:\n",
    "    print('This choice generates non-autonomous dynamics, letting the weights depend on time')\n",
    "\n",
    "possible_problem = {'moons':'moons', 'ToggleSwitch':'TS', 'repressilator':'repr', 'restricted_TS': 'restrictedTS'} \n",
    "# this choices determine the data set that we build and subsequent choices on the construction of the neural ODE \n",
    "# - in particular, it determines the dimensions \n",
    "problem = possible_problem[chosen_problem]\n",
    "\n",
    "plotlim = [0, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No change  applied to TS or repr data\n",
      "0\n",
      "[[4.765574  2.803489 ]\n",
      " [1.7676971 4.7275352]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "1\n",
      "[[3.788158  1.3965545]\n",
      " [2.0153463 3.6734223]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "2\n",
      "[[3.0734754 1.9050643]\n",
      " [3.1855717 2.3723054]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "3\n",
      "[[0.0213176  0.5278468 ]\n",
      " [1.4292123  0.13477415]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "4\n",
      "[[2.798193   2.7954621 ]\n",
      " [0.45728415 1.0500159 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "5\n",
      "[[4.1512594  0.63055456]\n",
      " [4.5373483  4.099635  ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "6\n",
      "[[2.8609877 2.7693775]\n",
      " [4.9341497 3.040148 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "7\n",
      "[[2.6746128  0.99401593]\n",
      " [3.2960584  3.2844515 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "8\n",
      "[[2.9896364 4.2264805]\n",
      " [4.7320514 1.4826515]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "9\n",
      "[[3.2789226 1.5101135]\n",
      " [2.3994823 3.886868 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "10\n",
      "[[2.2904232 2.4142828]\n",
      " [1.5624917 3.0751083]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "11\n",
      "[[0.74520856 2.4327657 ]\n",
      " [4.9283075  0.8420071 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "12\n",
      "[[2.3284373 1.1638341]\n",
      " [2.263605  2.9355612]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "13\n",
      "[[0.4590851  2.396903  ]\n",
      " [4.0527563  0.07553577]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "14\n",
      "[[2.8474746  0.02360106]\n",
      " [4.651264   3.6286612 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "15\n",
      "[[1.4866471 1.382977 ]\n",
      " [3.9867818 1.9343963]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "16\n",
      "[[0.8125809 3.119883 ]\n",
      " [4.649084  1.27947  ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "17\n",
      "[[2.1712062 2.6755478]\n",
      " [4.1510434 0.6193179]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "18\n",
      "[[2.4790316 2.2937832]\n",
      " [1.9803214 3.7606254]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "19\n",
      "[[4.8430147 0.9993309]\n",
      " [4.3996396 3.3109574]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "0\n",
      "[[2.8074179 0.8869821]\n",
      " [4.073567  1.6477106]\n",
      " [1.159333  3.9157753]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "1\n",
      "[[2.3678424  3.0679939 ]\n",
      " [0.0603652  0.19798398]\n",
      " [2.8369284  1.2690306 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "2\n",
      "[[1.8294873  3.5126126 ]\n",
      " [1.5517557  0.04850388]\n",
      " [3.2886803  0.97331226]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "3\n",
      "[[2.1412907 1.4443129]\n",
      " [2.1121335 1.7852619]\n",
      " [4.7884912 0.549767 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "4\n",
      "[[3.822146   1.875268  ]\n",
      " [0.37542343 2.6539109 ]\n",
      " [4.830137   1.3849308 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "5\n",
      "[[3.7588894  0.96445024]\n",
      " [0.31447232 4.5587583 ]\n",
      " [1.9138517  1.495015  ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "6\n",
      "[[4.1567388 2.7823825]\n",
      " [4.8210926 2.4931097]\n",
      " [3.4210017 0.9549254]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "7\n",
      "[[4.9234066  0.42592764]\n",
      " [2.6671815  1.0981843 ]\n",
      " [1.3085341  3.9858198 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "8\n",
      "[[3.1375887  3.6535623 ]\n",
      " [3.3866897  3.6905737 ]\n",
      " [4.957882   0.23652077]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "9\n",
      "[[0.61278015 4.67754   ]\n",
      " [4.679636   3.5188284 ]\n",
      " [3.768168   1.7092252 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "10\n",
      "[[4.503719  3.7318149]\n",
      " [2.3580685 4.3688335]\n",
      " [3.701321  3.9200246]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "11\n",
      "[[1.1488968 2.1092484]\n",
      " [1.3751268 2.5863261]\n",
      " [1.000548  2.637832 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "12\n",
      "[[4.3782682  1.3603339 ]\n",
      " [2.0702758  3.9286203 ]\n",
      " [0.56484103 2.896709  ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "13\n",
      "[[3.0929625 2.7936957]\n",
      " [0.9685397 1.6798598]\n",
      " [1.0042244 3.484862 ]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "14\n",
      "[[4.35895    0.5777341 ]\n",
      " [3.5285883  1.9207313 ]\n",
      " [3.6608095  0.05953461]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "15\n",
      "[[1.3103321  0.7376906 ]\n",
      " [4.6874943  0.94999045]\n",
      " [1.3034155  0.01677871]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "16\n",
      "[[2.4892058  2.177916  ]\n",
      " [0.06619394 2.5546002 ]\n",
      " [3.7912467  0.69129765]]\n",
      "restricted\n",
      "No change  applied to TS or repr data\n",
      "17\n",
      "[[3.9556549 3.2093368]\n",
      " [4.045662  0.8295426]\n",
      " [1.7776382 3.0946126]]\n",
      "restricted\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 66\u001b[0m\n\u001b[0;32m     62\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m     63\u001b[0m trainer_anode \u001b[38;5;241m=\u001b[39m doublebackTrainer(anode, optimizer_anode, device, cross_entropy\u001b[38;5;241m=\u001b[39mcross_entropy, turnpike \u001b[38;5;241m=\u001b[39m turnpike,\n\u001b[0;32m     64\u001b[0m                         bound\u001b[38;5;241m=\u001b[39mbound, fixed_projector\u001b[38;5;241m=\u001b[39mfp, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, eps_comp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m \u001b[43mtrainer_anode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m W1 \u001b[38;5;241m=\u001b[39m anode\u001b[38;5;241m.\u001b[39mflow\u001b[38;5;241m.\u001b[39mdynamics\u001b[38;5;241m.\u001b[39mfc1_time[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mweight\n\u001b[0;32m     69\u001b[0m W1 \u001b[38;5;241m=\u001b[39m W1\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Data\\Code\\BioML\\models\\training.py:80\u001b[0m, in \u001b[0;36mdoublebackTrainer.train\u001b[1;34m(self, data_loader, num_epochs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_loader, num_epochs):\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 80\u001b[0m         avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m     82\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, avg_loss))\n",
      "File \u001b[1;32mc:\\Data\\Code\\BioML\\models\\training.py:112\u001b[0m, in \u001b[0;36mdoublebackTrainer._train_epoch\u001b[1;34m(self, data_loader, epoch)\u001b[0m\n\u001b[0;32m    110\u001b[0m x_i \u001b[38;5;241m=\u001b[39m x_batch[i]\n\u001b[0;32m    111\u001b[0m y_i \u001b[38;5;241m=\u001b[39m y_batch[i]\n\u001b[1;32m--> 112\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    113\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum((y_pred \u001b[38;5;241m-\u001b[39m y_i)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# loss_trainer += self.loss_func(y_pred, y_i)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Data\\Code\\BioML\\models\\neural_odes.py:280\u001b[0m, in \u001b[0;36mNeuralODE.forward\u001b[1;34m(self, x, return_features)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, return_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 280\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow\u001b[38;5;241m.\u001b[39mtrajectory(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_steps)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m#pred = self.linear_layer(features)\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m#self.proj_traj = self.linear_layer(self.traj)\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m#if not self.cross_entropy:\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m#    pred = self.non_linearity(pred)\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m#    self.proj_traj = self.non_linearity(self.proj_traj)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Data\\Code\\BioML\\models\\neural_odes.py:221\u001b[0m, in \u001b[0;36mSemiflow.forward\u001b[1;34m(self, x, eval_times)\u001b[0m\n\u001b[0;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m odeint_adjoint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamics, x_aug, integration_time, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuler\u001b[39m\u001b[38;5;124m'\u001b[39m, options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_size\u001b[39m\u001b[38;5;124m'\u001b[39m: dt})\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# out = odeint_adjoint(self.dynamics, x_aug, integration_time, method='dopri5', rtol = 0.1, atol = 0.1)\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# ÃŸout = odeint(self.dynamics, x_aug, integration_time, method='euler', options={'step_size': dt})\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegration_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdopri5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# i need to put the out into the odeint for the adj_out\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# adj_out = odeint(self.adj_dynamics, torch.eye(x.shape[0]), torch.flip(integration_time,[0]), method='euler', options={'step_size': dt}) #this is new for the adjoint\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_times \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchdiffeq\\_impl\\odeint.py:77\u001b[0m, in \u001b[0;36modeint\u001b[1;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[0;32m     74\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchdiffeq\\_impl\\solvers.py:30\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_integrate(t)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[1;32m---> 30\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchdiffeq\\_impl\\rk_common.py:194\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[1;34m(self, next_t)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_t \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39minterp_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1, next_t)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchdiffeq\\_impl\\rk_common.py:255\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[1;34m(self, rk_state)\u001b[0m\n\u001b[0;32m    250\u001b[0m         dt \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m y1, f1, y1_error, k \u001b[38;5;241m=\u001b[39m \u001b[43m_runge_kutta_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtableau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[0;32m    265\u001b[0m error_ratio \u001b[38;5;241m=\u001b[39m _compute_error_ratio(y1_error, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrtol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matol, y0, y1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchdiffeq\\_impl\\rk_common.py:60\u001b[0m, in \u001b[0;36m_runge_kutta_step\u001b[1;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Take an arbitrary Runge-Kutta step and estimate error.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    func: Function to evaluate like `func(t, y)` to compute the time derivative of `y`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    calculating these terms.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m t0 \u001b[38;5;241m=\u001b[39m t0\u001b[38;5;241m.\u001b[39mto(y0\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m---> 60\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m t1 \u001b[38;5;241m=\u001b[39m t1\u001b[38;5;241m.\u001b[39mto(y0\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# We use an unchecked assign to put data into k without incrementing its _version counter, so that the backward\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# doesn't throw an (overzealous) error about in-place correctness. We know that it's actually correct.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "m1vec = []\n",
    "m2vec = []\n",
    "lossvec = []\n",
    "var1vec = []\n",
    "var2vec = []\n",
    "for sz in range(2,11):\n",
    "\n",
    "    m1vectemp = []\n",
    "    m2vectemp = []\n",
    "    lossvectemp = []\n",
    "    Xtempvec = []\n",
    "    W1vec = []\n",
    "\n",
    "    for k in range(0,20):\n",
    "        \n",
    "        ind = ind + 1\n",
    "        seed = ind\n",
    "\n",
    "        dataloader, dataloader_viz, X_train = create_dataloader(problem, batch_size = sz, noise = data_noise, \n",
    "                                                    plotlim = plotlim, random_state = seed, label = 'vector')\n",
    "        \n",
    "        print(k)\n",
    "        print(X_train.detach().numpy())\n",
    "\n",
    "        #Import of the model dynamics that describe the neural ODE\n",
    "        #The dynamics are based on the torchdiffeq package, that implements ODE solvers in the pytorch setting\n",
    "        from models.neural_odes import NeuralODE\n",
    "\n",
    "        #T is the end time of the neural ODE evolution, num_steps are the amount of discretization steps for the ODE solver\n",
    "        T, num_steps = 1, n_different_weights\n",
    "        bound = 0.\n",
    "        fp = False\n",
    "        cross_entropy = False\n",
    "        turnpike = False\n",
    "\n",
    "        # choice of model: what nonlinearity is used and if the nonlinearity is applied before (inside) or after (outside) the linear weights\n",
    "        # another choice is bottleneck, but I don't understand it\n",
    "        # non_linearity = 'tanh' # OR 'relu' 'sigmoid' 'leakyrelu' 'tanh_prime'\n",
    "        # architecture = 'inside' 'outside'\n",
    "        non_linearity = 'tanh'\n",
    "        architecture = 'restricted'\n",
    "        architectures = {'inside': -1, 'outside': 0, 'bottleneck': 1, 'restricted': 2}\n",
    "        # number of optimization runs in which the dataset is used for gradient decent\n",
    "        num_epochs = 50\n",
    "        if problem == 'moons' or problem == 'TS' or problem == \"restrictedTS\":\n",
    "            hidden_dim, data_dim = 2, 2 \n",
    "        else:\n",
    "            hidden_dim, data_dim = 3, 3 \n",
    "        augment_dim = 0\n",
    "\n",
    "        # resets the seed - allows for coherent runs in the gradient descent as well\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        anode = NeuralODE(device, data_dim, hidden_dim, output_dim=data_dim, augment_dim=augment_dim, non_linearity=non_linearity, \n",
    "                            architecture=architecture, T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "        optimizer_anode = torch.optim.Adam(anode.parameters(), lr=1e-1)\n",
    "\n",
    "        from models.training import doublebackTrainer\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        trainer_anode = doublebackTrainer(anode, optimizer_anode, device, cross_entropy=cross_entropy, turnpike = turnpike,\n",
    "                                bound=bound, fixed_projector=fp, verbose = False, eps_comp = 0.2)\n",
    "\n",
    "        trainer_anode.train(dataloader, 200)\n",
    "\n",
    "        W1 = anode.flow.dynamics.fc1_time[0].weight\n",
    "        W1 = W1.detach().numpy()\n",
    "        m1 = abs(W1[0][1]-W1[1][0])\n",
    "        m2 = abs(W1[0][0])+abs(W1[1][1])\n",
    "\n",
    "        lv = trainer_anode.histories[\"loss_history\"]\n",
    "        l = lv[-1]\n",
    "\n",
    "        m1vectemp.append(m1)\n",
    "        m2vectemp.append(m2)\n",
    "        lossvectemp.append(l)\n",
    "        Xtempvec.append(X_train.detach().numpy())\n",
    "        W1vec.append(W1)\n",
    "    \n",
    "    mdic = {\"X\":Xtempvec,\"l\":lossvectemp,\"symm\":m1vectemp,\"offdiag\":m2vectemp,\"W1\":W1vec}\n",
    "    io.savemat(\"restricted_n\"+str(sz)+\".mat\",mdic)\n",
    "    m1vec.append(np.mean(m1vectemp))\n",
    "    m2vec.append(np.mean(m2vectemp))\n",
    "    lossvec.append(np.mean(lossvectemp))\n",
    "    var1vec.append(np.var(m1vectemp))\n",
    "    var2vec.append(np.var(m2vectemp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
