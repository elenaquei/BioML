{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from numpy import mean\n",
    "sys.path.append(os.path.abspath(\"C:\\\\Data\\\\Code\\\\BioML_refactor\\\\models\"))\n",
    "sys.path.append(os.path.abspath(\"C:\\\\Data\\\\Code\\\\BioML_refactor\\\\utils\"))\n",
    "from boolODE_data_to_pyg_data import make_adj_from_df, to_pyg_data\n",
    "from training import easyTrainer, weights_to_dataset\n",
    "from nODE import nODE, make_nODE_from_parameters\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cpu'#torch.device('cuda' if torch.cuda.is_available() else 'cpu')''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load data, and take timepoint 0 as the initial condition for the ODE (x). Then, the full data matrix should be fitted using the ODE model (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../data/'\n",
    "name = 'dyn_linear'\n",
    "df=pd.read_csv(datadir + name + '/ExpressionData.csv', index_col=0)\n",
    "\n",
    "adj_df = pd.read_csv(datadir + name + '/refNetwork.csv', index_col=0)\n",
    "\n",
    "mat = df.to_numpy()\n",
    "\n",
    "sz = df.to_numpy().shape\n",
    "edge_index, adj = make_adj_from_df(datadir,df, name)\n",
    "true_data = to_pyg_data(mat, sz[0], sz[1], edge_index=edge_index)\n",
    "\n",
    "ode_dim = true_data.x.shape[0]\n",
    "\n",
    "num_features = 3000\n",
    "\n",
    "tp = []\n",
    "\n",
    "with open(datadir + name + '/PseudoTime.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for ln in reader:\n",
    "            tp.append(float(ln[1]))\n",
    "\n",
    "tp = torch.tensor(tp)\n",
    "\n",
    "x = true_data.x[:,966] # linear\n",
    "# x = true_data.x[:,2943] # bifurcating\n",
    "y = true_data.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove 2 connections from the network. This allows us to compare a model that works from a model that does not work (should be replaced by actual GAE results later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate imputed data where some edges are missing\n",
    "p = 0.1\n",
    "rem = []\n",
    "while len(rem) != 1:\n",
    "    rem = []\n",
    "    imputed_edge_index = true_data.edge_index\n",
    "    while len(rem) == 0:\n",
    "        for k in range(0,len(true_data.edge_index[0])):\n",
    "            if random.random() < p:\n",
    "                rem.append(k)\n",
    "\n",
    "mask = torch.ones(imputed_edge_index.shape[1], dtype=torch.bool)\n",
    "mask[rem] = False\n",
    "\n",
    "imputed_edge_index = imputed_edge_index[:,mask]\n",
    "\n",
    "# data has MOST edges\n",
    "data = copy.deepcopy(true_data)\n",
    "data.edge_index = imputed_edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get masks for true network and imputed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ode_dim = true_data.x.shape[0]\n",
    "mask_true = torch.zeros((ode_dim,ode_dim))\n",
    "mask_incorrect = torch.zeros((ode_dim,ode_dim))\n",
    "\n",
    "true_e = true_data.edge_index\n",
    "e = data.edge_index\n",
    "\n",
    "for k in range(0,len(true_e[0])):\n",
    "    mask_true[true_e[0][k],true_e[1][k]] = 1\n",
    "\n",
    "for k in range(0,len(e[0])):\n",
    "    mask_incorrect[e[0][k],e[1][k]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tsTrainer():\n",
    "    def __init__(self, model, optimizer, device, x0, y, tp, mask,\n",
    "                 print_freq=10, record_freq=10, verbose=1, save_dir=None,\n",
    "                 l2_factor=0, db_type='l1'):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "        self.print_freq = print_freq\n",
    "        self.record_freq = record_freq\n",
    "        self.steps = 0\n",
    "        self.save_dir = save_dir\n",
    "        self.verbose = verbose\n",
    "        self.x0 = x0\n",
    "        self.y = y\n",
    "        self.tp = tp\n",
    "        self.mask = mask\n",
    "\n",
    "        self.histories = {'loss_history': [],\n",
    "                          'epoch_loss_history': []}\n",
    "        self.buffer = {'loss': []}\n",
    "        self.is_resnet = (type(self.model).__name__ == 'resnet')\n",
    "        self.is_nODE = (type(self.model).__name__ == 'nODE')\n",
    "        self.l2_factor = l2_factor\n",
    "        self.db_type = db_type\n",
    "\n",
    "    def interpolate_solution(self,t_query, t_solution, y_solution):\n",
    "        t_query = t_query.to(t_solution.device)  # Ensure same device\n",
    "        indices = torch.searchsorted(t_solution, t_query, right=True) - 1\n",
    "        indices = torch.clamp(indices, 0, len(t_solution) - 2)  # Clamp to valid range\n",
    "\n",
    "        t0, t1 = t_solution[indices], t_solution[indices + 1]\n",
    "        y0, y1 = y_solution[indices], y_solution[indices + 1]\n",
    "\n",
    "        # Linear interpolation formula: y = y0 + (y1 - y0) * (t_query - t0) / (t1 - t0)\n",
    "        slope = (y1 - y0) / (t1 - t0).unsqueeze(-1)\n",
    "        y_interp = y0 + slope * (t_query - t0).unsqueeze(-1)\n",
    "\n",
    "        return y_interp\n",
    "\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            avg_loss = self._train_epoch()\n",
    "            if self.verbose:\n",
    "                print(\"Epoch {}: {:.3f}\".format(epoch + 1, avg_loss))         \n",
    "            \n",
    "    def _train_epoch(self):\n",
    "        loss = 0.\n",
    "\n",
    "        y_pred = self.model(self.x0, return_features=True)\n",
    "        sim_time = torch.linspace(0, 1, 300)\n",
    "\n",
    "        ref = torch.zeros(y.shape)\n",
    "        for i in range(0, len(tp)):\n",
    "            ref[:,i] = self.interpolate_solution(tp[i],sim_time,y_pred)\n",
    "        # # Classical empirical risk minimization\n",
    "        \n",
    "        loss = self.loss_func(ref, y)\n",
    "\n",
    "        l1_loss = torch.abs(self.model.inside_weights.weight)[self.mask == 0].sum()\n",
    "\n",
    "        #loss = loss + 1000*l1_loss\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # epoch_loss += loss.item()\n",
    "\n",
    "        self.buffer['loss'].append(loss.item())\n",
    "\n",
    "        # At every record_freq iteration, record mean loss and clear buffer\n",
    "        if self.steps % self.record_freq == 0:\n",
    "            self.histories['loss_history'].append(mean(self.buffer['loss']))\n",
    "\n",
    "            # Clear buffer\n",
    "            self.buffer['loss'] = []\n",
    "\n",
    "        self.steps += 1\n",
    "\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3000\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'epoch_loss' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 44\u001b[0m, in \u001b[0;36mtsTrainer.train\u001b[1;34m(self, num_epochs)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_epochs):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 44\u001b[0m         avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m     46\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, avg_loss))\n",
      "Cell \u001b[1;32mIn[9], line 68\u001b[0m, in \u001b[0;36mtsTrainer._train_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 68\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# At every record_freq iteration, record mean loss and clear buffer\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'epoch_loss' referenced before assignment"
     ]
    }
   ],
   "source": [
    "node = nODE(ode_dim, architecture='both', time_interval=[0, 1])\n",
    "\n",
    "optimizer_node = torch.optim.Adam(node.parameters(), lr=0.0001)\n",
    "\n",
    "trainer = tsTrainer(node, optimizer_node, device, x, y, tp, mask_incorrect, verbose=1)\n",
    "print()\n",
    "print(y.shape[1])\n",
    "trainer.train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0343,  0.0008, -0.0226,  0.0245,  0.0042, -0.0239,  0.0053],\n",
      "        [ 0.0122,  0.0027,  0.0021,  0.0140,  0.0197,  0.0272,  0.0117],\n",
      "        [-0.0172,  0.0345, -0.0331,  0.0104, -0.0187, -0.0123, -0.0325],\n",
      "        [ 0.0219, -0.0053,  0.0080,  0.0236,  0.0231, -0.0155,  0.0053],\n",
      "        [-0.0521,  0.0064, -0.0431,  0.0272, -0.0238, -0.0066, -0.0107],\n",
      "        [-0.0288,  0.0093, -0.0129,  0.0222, -0.0046, -0.0153, -0.0118],\n",
      "        [ 0.0196, -0.0262,  0.0420, -0.0139, -0.0045,  0.0566,  0.0078]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "node.inside_weights.weight\n",
    "node.outside_weights.weight\n",
    "print(torch.matmul(node.outside_weights.weight, node.inside_weights.weight))\n",
    "print(mask_incorrect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
