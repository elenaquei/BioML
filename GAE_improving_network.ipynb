{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from torch_geometric.utils.dropout import dropout_adj\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.boolODE_data_to_pyg_data import make_adj_from_df, to_pyg_data\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set user parameters:\n",
    "#   datadir: directory in which data in the BoolODE format is available\n",
    "#   name: name of the directory in which the data is located (subdirectory of datadir)\n",
    "#   filenm: name under which the results should be saved for this network, note: output/\"+filenm+\"/\"+filenm+\"/\" should exist before running!\n",
    "#   num_features: amount of cells available for the data (2000 for mCAD example network)\n",
    "datadir = 'data/'\n",
    "name = 'mCAD/mCAD-2000-1'\n",
    "filenm = 'mCAD_new'\n",
    "num_features = 2000\n",
    "\n",
    "# read out adjacency matrix and reference (true) network \n",
    "df=pd.read_csv(datadir + name + '/ExpressionData.csv', index_col=0)\n",
    "adj_df = pd.read_csv(datadir + name + '/refNetwork.csv', index_col=0)\n",
    "mat = df.to_numpy()\n",
    "\n",
    "# construct Pytorch Geometric data object based on the input\n",
    "sz = df.to_numpy().shape\n",
    "edge_index, adj = make_adj_from_df(datadir,df, name)\n",
    "true_data = to_pyg_data(mat, sz[0], sz[1], edge_index=edge_index)\n",
    "\n",
    "ode_dim = true_data.x.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Graph Autoencoder (GAE) Model\n",
    "\n",
    "class GAE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=16):\n",
    "        super(GAE, self).__init__()\n",
    "\n",
    "        # first graphSAGE layer\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "\n",
    "        # second graphSAGE layer\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "\n",
    "        # one linear layer (only weights) for decoding\n",
    "        self.lin1 = torch.nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "\n",
    "    # encode node features\n",
    "    def encode(self, data):\n",
    "\n",
    "        # dropout edges to avoid overfitting\n",
    "        edge_index = dropout_adj(data.edge_index, p = 0.2)[0]\n",
    "\n",
    "        # apply first graphSAGE layer + activation function (ReLU)\n",
    "        x = self.conv1(data.x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # apply dropout layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # apply second graphSAGE layer and return\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    # decode specific edges\n",
    "    def decode(self, z, edge_index):\n",
    "        return (z[edge_index[0]] * self.lin1(z[edge_index[1]])).sum(dim=-1)  # Inner product\n",
    "    \n",
    "    # decode all edges for full adjacency matrix inference\n",
    "    def decode_all(self,z):\n",
    "        adj_matrix = torch.ones((z.shape[0], z.shape[0]))\n",
    "        full_edge_index = adj_matrix.nonzero().t().contiguous()\n",
    "        \n",
    "        # inner product decoder with linear weights applied (lin1)\n",
    "        return (z[full_edge_index[0]] * self.lin1(z[full_edge_index[1]])).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for one training step\n",
    "def train(model, data, query, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # run data through encoder\n",
    "    z = model.encode(data)\n",
    "\n",
    "    # find appropriate negative examples of edges (not known edges, nor the edge that we want to predict)\n",
    "    neg_edges = negative_sampling(torch.cat([data.edge_index,query],dim=1), data.num_nodes, data.edge_index.size(1))\n",
    "    edges = torch.cat([data.edge_index, neg_edges], dim=1)\n",
    "    \n",
    "    # set labels: 1 for real edges, 0 for negative samples\n",
    "    labels = torch.cat([torch.ones(data.edge_index.size(1)), torch.zeros(neg_edges.size(1))]).to(data.x.device)\n",
    "\n",
    "    # decode for the true edges in the given GRN + the negative sampled edges\n",
    "    preds = model.decode(z, edges)\n",
    "    \n",
    "    # optimization step\n",
    "    loss = criterion(preds, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# code for training a model (multiple epochs)\n",
    "def train_model(data, query, device):\n",
    "\n",
    "    # initialise GAE model\n",
    "    model = GAE(input_dim=num_features,hidden_dim=200)\n",
    "    model.to(device)\n",
    "\n",
    "    # set optimiser and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    loss_vec = []\n",
    "\n",
    "    # train for 1000 epochs\n",
    "    for epoch in range(1000):\n",
    "        loss = train(model, data, query, optimizer, criterion)\n",
    "        \n",
    "        loss_vec.append(loss)\n",
    "\n",
    "    # return the trained GAE model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first edge is removed from the true given GRN (as an example, in a practical use case this step can be skipped, as no edge needs to be removed)\n",
    "rem = 0\n",
    "imputed_edge_index = true_data.edge_index\n",
    "\n",
    "mask = torch.ones(imputed_edge_index.shape[1], dtype=torch.bool)\n",
    "mask[rem] = False\n",
    "\n",
    "imputed_edge_index = imputed_edge_index[:,mask]\n",
    "\n",
    "# create a new data object that has all gene expression data, and one fewer edge than the original data (the i-th edge)\n",
    "data = copy.deepcopy(true_data)\n",
    "data.edge_index = imputed_edge_index\n",
    "\n",
    "# next, we find all edges that we want to predict, starting from a fully connected network\n",
    "adj_matrix = torch.ones((ode_dim, ode_dim))\n",
    "\n",
    "query_edge_index = adj_matrix.nonzero().t().contiguous()\n",
    "\n",
    "# we remove all edges that are already in the given GRN from the edges to query\n",
    "rem_query = []\n",
    "for k in range(0,len(query_edge_index[0])):\n",
    "    for j in range(0,len(data.edge_index[0])):\n",
    "        if query_edge_index[0][k] == data.edge_index[0][j] and query_edge_index[1][k] == data.edge_index[1][j]:\n",
    "            rem_query.append(k)\n",
    "\n",
    "mask = torch.ones(query_edge_index.shape[1], dtype=torch.bool)\n",
    "mask[rem_query] = False\n",
    "\n",
    "query_edge_index = query_edge_index[:,mask]\n",
    "\n",
    "# set device and move data to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "# adj is the inferred adjacency matrix, whereas count_adj counts how many times an edge has been predicted (in case multiple runs are used)\n",
    "adj = torch.zeros((ode_dim, ode_dim))\n",
    "count_adj = torch.zeros((ode_dim, ode_dim))\n",
    "\n",
    "# we train the GAE once for each query edge, resulting in a predicted adjacency matrix\n",
    "for k in range(0,len(query_edge_index[0])):\n",
    "\n",
    "    # set queried edge\n",
    "    query = torch.tensor([[query_edge_index[0][k]],[query_edge_index[1][k]]])\n",
    "    query = query.to(device)\n",
    "\n",
    "    # train a new model to predict whether the queried edge is in the GRN\n",
    "    model = train_model(data, query, device)\n",
    "    model.eval()\n",
    "    \n",
    "    # use trained model to predict queried edge\n",
    "    z = model.encode(data)\n",
    "    dec = model.decode(z, query)\n",
    "\n",
    "    # add each queried edge to the adjacency matrix\n",
    "    for k in range(0, len(query[0])):\n",
    "        adj[query[0][k], query[1][k]] = torch.sigmoid(dec[k])\n",
    "        count_adj[query[0][k], query[1][k]] += 1\n",
    "\n",
    "from scipy.io import savemat\n",
    "\n",
    "# if edges are inferred multiple times, divide by the number of times they have reappeared\n",
    "inferred_adj = (adj/count_adj).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for edge 1/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JansenKlompLF\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch_geometric\\deprecation.py:21: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m query \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# train a new model to predict whether the queried edge is in the GRN\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# use trained model to predict queried edge\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 40\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(data, query, device)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# train for 1000 epochs\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m---> 40\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     loss_vec\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# return the trained GAE model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data, query, optimizer, criterion)\u001b[0m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds, labels)\n\u001b[0;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 22\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\adam.py:412\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m--> 412\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training procedure for benchmarking a known true network (looping over edges, removing then and then using GAE to predict), see above for more concise code to be used if one prediction is desired based on a given network\n",
    "for i in range(0,len(true_data.edge_index[0])):\n",
    "\n",
    "    # i-th edge is removed from the true given GRN\n",
    "    rem = i\n",
    "    imputed_edge_index = true_data.edge_index\n",
    "\n",
    "    mask = torch.ones(imputed_edge_index.shape[1], dtype=torch.bool)\n",
    "    mask[rem] = False\n",
    "\n",
    "    imputed_edge_index = imputed_edge_index[:,mask]\n",
    "\n",
    "    # create a new data object that has all gene expression data, and one fewer edge than the original data (the i-th edge)\n",
    "    data = copy.deepcopy(true_data)\n",
    "    data.edge_index = imputed_edge_index\n",
    "\n",
    "    # next, we find all edges that we want to predict, starting from a fully connected network\n",
    "    adj_matrix = torch.ones((ode_dim, ode_dim))\n",
    "\n",
    "    query_edge_index = adj_matrix.nonzero().t().contiguous()\n",
    "\n",
    "    # we remove all edges that are already in the given GRN from the edges to query\n",
    "    rem_query = []\n",
    "    for k in range(0,len(query_edge_index[0])):\n",
    "        for j in range(0,len(data.edge_index[0])):\n",
    "            if query_edge_index[0][k] == data.edge_index[0][j] and query_edge_index[1][k] == data.edge_index[1][j]:\n",
    "                rem_query.append(k)\n",
    "\n",
    "    mask = torch.ones(query_edge_index.shape[1], dtype=torch.bool)\n",
    "    mask[rem_query] = False\n",
    "\n",
    "    query_edge_index = query_edge_index[:,mask]\n",
    "\n",
    "    # set device and move data to device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    data = data.to(device)\n",
    "\n",
    "    # adj is the inferred adjacency matrix, whereas count_adj counts how many times an edge has been predicted (in case multiple runs are used)\n",
    "    adj = torch.zeros((ode_dim, ode_dim))\n",
    "    count_adj = torch.zeros((ode_dim, ode_dim))\n",
    "\n",
    "    # we train the GAE once for each query edge, resulting in a predicted adjacency matrix\n",
    "    print(\"Training for edge \"+str(i+1)+\"/\"+str(len(true_data.edge_index[0])))\n",
    "\n",
    "    for k in range(0,len(query_edge_index[0])):\n",
    "\n",
    "        # set queried edge\n",
    "        query = torch.tensor([[query_edge_index[0][k]],[query_edge_index[1][k]]])\n",
    "        query = query.to(device)\n",
    "\n",
    "        # train a new model to predict whether the queried edge is in the GRN\n",
    "        model = train_model(data, query, device)\n",
    "        model.eval()\n",
    "        \n",
    "        # use trained model to predict queried edge\n",
    "        z = model.encode(data)\n",
    "        dec = model.decode(z, query)\n",
    "\n",
    "        # add each queried edge to the adjacency matrix\n",
    "        for k in range(0, len(query[0])):\n",
    "            adj[query[0][k], query[1][k]] = torch.sigmoid(dec[k])\n",
    "            count_adj[query[0][k], query[1][k]] += 1\n",
    "\n",
    "    from scipy.io import savemat\n",
    "\n",
    "    # if edges are inferred multiple times, divide by the number of times they have reappeared\n",
    "    inferred_adj = (adj/count_adj).detach().numpy()\n",
    "\n",
    "    # save inferred adjacency to a .mat file\n",
    "    i1 = true_data.edge_index[:,i][0].numpy()\n",
    "    i2 = true_data.edge_index[:,i][1].numpy()\n",
    "    savemat(\"output/\"+filenm+\"/\"+filenm+\"_\"+str(i1)+\"_\"+str(i2)+\".mat\",{\"inferred_adj\": inferred_adj})\n",
    "\n",
    "    inferred_adj = (adj/count_adj).detach().numpy()\n",
    "    N = inferred_adj.shape[0]\n",
    "\n",
    "    # Ground truth positive edges\n",
    "    pos_edges = set((i.item(), j.item()) for i, j in edge_index.t())\n",
    "\n",
    "    # All possible (i, j) pairs excluding self-loops\n",
    "    all_edges = [(i, j) for i in range(N) for j in range(N)]\n",
    "\n",
    "    # optional computation of AUROC for predicted edge\n",
    "    y_true = []\n",
    "    y_score = []\n",
    "\n",
    "    for i, j in all_edges:\n",
    "        score = inferred_adj[i, j].item()\n",
    "        # skip all NaN values (edges that we already knew)\n",
    "        if math.isnan(score):\n",
    "            continue\n",
    "        y_true.append(1 if (i, j) in pos_edges else 0)\n",
    "        y_score.append(score)\n",
    "\n",
    "    auroc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
